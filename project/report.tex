\documentclass[sigconf]{acmart}

\input{format/i523}

\definecolor{light-gray}{gray}{0.95}
\usepackage{caption}
\usepackage{listings} %code extracts
\usepackage{xcolor} %custom colours
\usepackage{mdframed} %nice frames

\mdfsetup{skipabove=5pt,skipbelow=5pt}
\mdfdefinestyle{default}{%
backgroundcolor=light-gray, roundcorner=10pt,
leftmargin=1, rightmargin=1, innerleftmargin=10, 
innertopmargin=2,innerbottommargin=2, outerlinewidth=1,
linecolor=light-gray}
\lstset{breaklines=true, basicstyle=\tiny}

\begin{document}
\title{The Impact of Clinical Trial Results on Pharmaceutical Stock Performance}

\author{Tiffany Fabianac} 
 \affiliation{% 
   \institution{Indiana University} 
   \city{Bloomington}  
   \state{Indiana}  
   \postcode{47408} 
   \country{USA}
 } 
 \email{tifabi@iu.edu} 
 \renewcommand{\shortauthors}{T. Fabianac} 

\begin{abstract}
While many relate stock market trading to gambling, successful traders have turned stock picking into a science. The likes of Warren Buffet tell us that successful stock buying is all in the research. So what kind of research aids in the prediction of companies within the highly volatile pharmaceutical market? The use of available, open-source APIs and Google Alerts are used to explore if clinical trial results can directly impact stock performance in small, mid, and large cap pharmaceutical companies. Key words and/or phrases in results and related news articles are identified as possible predictors of market effect. As well as a comparison to already established analyst ratings from Barclays, Goldman, Morningstar, or others which have already been shown to impact stock performance.
\end{abstract}

\keywords{Big Data, HID313, i523, Stock Market, Pharmaceutical}
\maketitle
\section{Introduction}
A ``stock'' is a piece of ownership in a company. Offering stocks for sale provides capital to the selling company in exchange for a stake in the company. A stock market is a collection of exchanges where trading of stocks takes place \cite{www-investopedia}. Evidence of early stock markets date back to the fourteenth century with the offering of state loan stocks throughout Italy. Even prior to the organization of stock markets, price fluctuations for goods such as wheat and barley were tracked by early economists. The first ``modern'' stock market appeared in Amsterdam in the seventeenth century where the volume of stocks traded and the fluidity in which they were traded reached a new high \cite{Braudel}. 

The biggest stock markets in the world are currently the New York Stock Exchange (NYSE), the National Association of Securities Dealers Automated Quotations (NASDAQ), and the London Stock Exchange. NYSE did stuff... NASDAQ began as an all-electric equities exchange in 1971 and today provides trading, technology, and information services for financial markets. Today   \cite{www-nasdaq}.

Throughout the history of markets, prices have been tracked and insightful traders have attempted to predict and capitalize on price fluctuation. The age of computers opened new doors for stock analysis and trend prediction to facilitate capital gains for traders. Financial companies like Goldman Sachs and JPMorgan Chase \& Co. have hired mathematicians, statisticians, and trade analysts since the early days of trading in an effort to predict the market in a consistent manner. Once an algorithm is established and used consistently the algorithm itself but be considered as a variable that could effect the prediction outcome \cite{Hellstrom}. 

A major complexity in creating algorithms for the stock market is that the market tends to follow the erratic emotions and feelings of humans. If computers were running the market, making trade decisions based on logic and reason, then the market would be much more stable. The volatility of human emotions about money and stocks creates tremendous volatility in the market. The revolution of social media has provided a means of measuring the mood of possible traders. For this reason, the ability to predict society's reaction to news has developed into a field of study within the data science world \cite{BOLLEN}. 

How big of an impact can news articles have on the stock market? In September 2008, an article published on a South Florida News website reported that United airlines had files Chapter 11 bankruptcy. The news struck so hard that United's stock plummeted 75\% from \$12 to \$3. Interestingly enough, the article was just about six years old and had originally been published by the Chicago Tribune in December 2002. Even though the report was literally ``old news'' it did not prevent massive panic from investors \cite{www-chTrib}.



\subsection{Pharmaceutical Sector}
The pharmaceutical industry has evolved around the need to establish drugs and treatment options for diseases. Research and development within pharmaceutical companies range from compound identification to disease characterization. This market is directly affected by the results of drug tests such as clinical trials and the establishment of new treatment options. Market growth also comes from manufacturing and licensing of drugs and treatment methods. Innovation is the key driver of this industry \cite{Gassmann}.

Like the financial sector trying to predict the stock market, the pharmaceutical industry has devoted resources to developing prediction algorithms and machine learning systems. The efforts of drug manufacturers are aimed to create a system that consistently predicts or aids in identifying drug targets. One such approac is the development or virtual screening for drug discovery meant to reduce the experimental failures associated with high throughput screening. High throughout screening is carried out to test many chemicals, molecules, compounds, proteins, hormones, viral vectors, etc all at once on large grids or plates which can test many different treatment combinations all together. Large costs and big data sets are associated with high throughput screening which is now becoming virtual with the help of advanced molecular profiling \cite{kitchen}.



\subsection{Clinical Trials}
A clinical trial is a planned experiment involving patients with the intent to elucidate an appropriate or effective treatment option(s) for the population of patients afflicted with the same medical condition. A big concern with clinical trials is that inferences are made for the entire population of patients from a relatively small sample size \cite{Pocock}. One of the first clinical trials recorded was carried out in the eighteenth century to evaluate six treatments on  twelve patients with scurvy. Two patients that were given oranges and lemons recovered very quickly. Fisher introduced the concept of randomization in the nineteenth century \cite{Friedman}.

Clinical trials have four defined phases. Phase I trials identify how well a drug is tolerated by determining the maximally tolerated doe (MTD) on a very small sample size. Phase I trials have very simple experimental designs as the only intent is to examine toxicity. Phase II explores biological activity or effect on a small patient sample size. The design of a Phase II trial is dependent on the design on the Phase I trial as both share the intent to evaluate adverse events. Phase III trials follow the design of Phase II trials but on a bigger sample size with the intent to solidify a treatment's effectiveness in clinical practice. Phase IV trials are prolonged Phase III trials that can track a drug, procedure, or instrument for decades with continues efficiency reflection \cite{Friedman}. 

Clinical trial designs have been very slow to evolve due to restricts enforced by governing agencies such as the US Food and Drug Administration (FDA) and the Centers for Disease Control and Prevention (CDC). While these restrictions are intended to minimize patient risk, they also greatly restrict the potential of clinical trial data collection. Other limiting factors include  difficulty enrolling high quality participants for each trial phase, problems monitoring how well patients are following protocol, difficulty sorting out ``the placebo effect'' or the ability for patients to feel as if they are recovering without actually receiving treatment, and overall minimizing poor quality of data \cite{Friedman}. 

\subsection{Established Analyst Ratings}
%Where did these rankings come from?
Companies within the financial sector often publish rankings of the top stocks that the company invests in. The ratings are a way to attract investors with proof that the company is diligently analyzing the market and ``picking winners''. These published rankings have been show to boost or deflate rallies behind particular stocks that are added or removed for these prestigious lists \cite{www-seekAnalyst}. 

The Goldman Sachs Group, Inc. was founded in 1869. The company provides a full stack portfolio of banking and investment services. Goldman Sachs career website states that the company is driven to achieve superior returns for their clients which include pension funds, hedge funds, and mutual funds. The company boasts that their research analysts are curious and creative \cite{www-gldmanGlance}. Goldman Sachs Global Investor Research group provides stock ratings on a scale of Buy, Neutral, and Sell \cite{www-goldmanTicker}. 

%Chase

%Morningstar



\subsection{Data Resources}
%Explain API, Machine Learning Tech,Text Mining  how they are used what they are
An Application Programming Interface (API) acts as the middleman between the requesting service and the preforming service. When a user or system submits a request the request is passed to the API which translates it for the processing system then returns the results in a receivable format. 

NASDAQ's website provides historical stock performance data that can be exported as a Comma-Separated Values (CSV) file. The disadvantage of NASDAQ's free export service is that each stock must be exported separately. The free quote service can be accessed at \cite{www-quotenasdaq}. NASDAQ provides API services for subscribers starting at \$5,000 per year \cite{www-nasdaq-sub}. Access to NASDAQ's API services can also be granted through corporate sponsorship. NASDAQ's free CSV export services were used to collect initial project data. In example, the stock history for Celsion Corporation during the week of August 21, 2017 is shown.

\begin{mdframed}[style=default]
\begin{lstlisting}
date,close,volume,open,high,low
2017/08/25,1.3700,179097.0000,1.3600,1.4100,1.3000
2017/08/24,1.3600,149832.0000,1.3100,1.3600,1.2810
2017/08/23,1.3100,223451.0000,1.2500,1.3300,1.2430
2017/08/22,1.2800,164594.0000,1.3200,1.3200,1.2400
2017/08/21,1.3300,169037.0000,1.3300,1.3700,1.2800
\end{lstlisting}
\end{mdframed} 

Exports such as this one offered by NASDAQ and API interfaces for stock data are provided by numerous companies. The Yahoo! Finance API is explored below and the Google Finance API was used to perform the stock data extraction for the analysis presented. Additional resources such as stock tracking apps and free exports are available. CSV exports such as the one listed above can be downloaded from Google Finance, Yahoo! Finance, and many others. This publication does not provide a complete list of available resources, but attempts to present a few for comparison. 

Python.org provides a python module to pull stock data from Yahoo! Finance \cite{www-python-yahoo}. The package can be installed through Git by cloning the Git directory where the package is available: \cite{www-yahooStock}. To install the python package without Git the tape archive can be downloaded from \cite{www-pythonYahooStock}.  Tape archives allow for compression of multiple files which can be restored to their original format using the tar command in the command line \cite{www-tar}.  Apply the tar options: z - filter archive through gzip, x - extract an archive file, and f - filename of archive, use ``cd'' to change the current working directory, and then install the python module using the package management command ``pip'':
\begin{mdframed}[style=default]
\begin{lstlisting}
tar -zxf yahoo-finance-1.4.0.tar.gz
cd yahoo-finance
pip install yahoo-finance
\end{lstlisting}
\end{mdframed}
While Yahoo! Finance is a great resource, the API does not function consistently, and as of this writing the API has been turned off by Yahoo!.


\section{Methods}
\subsection{Data Collection}
%news articles from Google Alerts for text mining
Data collection was initiated with the use of Google Alerts. Google allows for alerts to be configures from Google \cite{www-googleAlerts}. Gmail users can configure these alerts to be sent through email when news or other types of articles pertaining to a defined subject are released to the web. The Google Alerts for this project were: ``Phase III Trial'', ``Phase 3 Trial'', and ``Meets Primary End Point''. When these phrases are detected by Google, the link to the webpage and a short description are sent via email to the configured email address. On busy days, an excess of 100 alerts were received for these alert phrases. On slow days, only a couple alerts were received.  Only very infrequently were no messages received. 

To collect data from the received Google Alerts without too much manual clicking, Gmail has an available API which allows users to pull data from a Gmail account. To start using the Gmail API, a user must first configure their Authentication credentials through Google's developer console. Once credentials are received in the form of a JSON file, the Google Client Library can be installed using pip to install google-api-python-client. The Google Development team has provided a quickstart file which facilitates the first authentication run. Running this quick start guide will open a browser window and prompt the user to log into a Gmail account. The user then accepts the authorization and can run the Gmail API from command line or other compilers. 

 Headlines of the received alerts, usually the title of the article and the first couple of lines, are referred to as ``Snippets'' by Google's Gmail API. This project pulled only the Snippets and the date from the Google Alerts. The Snippets do not contain the whole article but may still provide enough evidence of sentiment for further analysis and prediction of the associated stock. Unfortunately, no solution was identified for extracting the appropriate stock symbols from the Snippets so this task had to be performed manually. 

The Python code calls the Gmail API and writes a .csv from the data. After calling all needed libraries, the scope of the authorization is defined. Google mail can be opened with a Readonly or Modify authentication. Next, the credentials are established by the JSON file received during the API authentication setup. This JSON must be saved in the same directory as the code being run. The code sets the variables for User ID and Label then runs an execution command calling the  Messages.List API, which looks like this:
\begin{mdframed}[style=default]
\begin{lstlisting}
GMAIL.users().messages().list(userId='me', labelIds=[INBOX], q='from:googlealerts-noreply@google.com before:2017/11/24').execute()
\end{lstlisting}
\end{mdframed}
Google has defined the user ID ``me'' as the global for the authenticated account in use. The labe lID ``INBOX'' designates that the messages will be pulled from the inbox folder, but any other folder could be called here as well as a collection of labels that Google has defined such as ``UNREAD''. The ``q'' designates a query. The query will return only messages from the Google Alerts email address which have been received by the twenty-fourth of November 2017. This data was selected so that all returned records would have five market days of stock prices to compare. This execution returns a dictionary which contains message IDs for all the messages that matched the query.

The next step is to ``get'' the messages with the use of the Messages.Get API. While looping through the dictionary of message ID from the defined query, the script retrieves the Date and Snippet for each. Additional options could return the Sender, Receiving Email, Email body, among others. The syntax is shown here:
\begin{mdframed}[style=default]
\begin{lstlisting}
GMAIL.users().messages().get(userId='me', id=m_id).execute()
\end{lstlisting}
\end{mdframed}
The user ID is the same as described previously with the ID being the current message ID within the loop. This execute command returns a dictionary which is parsed fron ``payload'' to ``headers'' to extract the Date. The Snippet is also grabbed from the message dictionary and along with the Date, passed to a final list to be written to a .csv file. 

\begin{figure}[htb]
\begin{verbatim}
your code here 
\end{verbatim}
\caption{The Google API Python code calls the Gmail APIs Messages.list which lists reduced properties of Gmail messages and Messages. Get which returns the messages themselves. Lists is used to query the messages that are wanted based on the defined criteria: userId=me, labelIds=INBOX], q=from:googlealerts-noreply@google.com. Get then retrieves the messages identified in using List and returns the messages content for Date and Snippet.}\label{c:googleapi}
\end{figure}

Figure \ref{c:googleapi} shows the entire code to extract Google Alerts data using the Google provided Gmail API.


The Python package pandas is an incredible resource that provides a number of tools to read, parse, extract, and manipulate delimited file or data types. The Pandas package has a resource for getting stock market data from free online sources such as Yahoo! mentioned above and Google. To install this package through Git, simply clone the directory, use the ``Change Directory'' command ``cd'' to change the current working directory, and installing the python module as follows: 

\begin{mdframed}[style=default]
\begin{lstlisting}
$ git clone git://github.com/pydata/pandas-datareader.git
$ cd pandas-datareader
$ python setup.py install
\end{lstlisting}
\end{mdframed}

If the Python setup returns the error: ``python: command not found'' run the following with the path to the python installation:
\begin{mdframed}[style=default]
\begin{lstlisting}
$ PATH="$PATH:/c/Python27"
\end{lstlisting}
\end{mdframed}

Pandas-datareader and many other packages can also be installed via pip. In example, many additional packages are needed to run a python script using pandas-datareader. These packages can be configured all at once or one at a time as follows:
\begin{mdframed}[style=default]
\begin{lstlisting}
pip -m install --user numpy scipy matplotlib ipython jupyter pandas sympy nose urllib3 chardet idna
\end{lstlisting}
\end{mdframed}

Unlike the NASDAQ export, using Google as a data source for pandas-datareader requires each attribute to be called separately. This means calling the Close Price, Open Price, High Price, etc individually and joining them through code. Also, unlike NASDAQ's export but this time in a positive light, multiple tickers can be passed together. This allows for all historical data to be pulled for many stocks with a single code. 

The Python code for collecting historical stock data is propelled by pandas\_datareader. The script starts by reading in the .csv created using the Google API script described previously. The data is read in as a dictionary using DictReader and the output file is opened/created right afterwards to allow for writing out with each loop through the starting file's dictionary. For each line the stock ticker and date of the Google Alert are passed to a function that returns the highest price of the stock 5 days after the Google Alert, the stock and ticker are then passed to a function that pulls the opening price on the day that the Google Alert was received. The highest price and starting price are the used to calculate the percent change using the formula: 
\begin{mdframed}[style=default]
\begin{lstlisting}
round(((high-startPrice)/startPrice)*100,2)
\end{lstlisting}
\end{mdframed}
If the high price is 10\% higher than the starting price the line is given a ``W'' for ``Winner''. If the high price is less than 10\% of the starting price then the line is marked with a ``L'' for loser. The whole line with the addition of the Win or Lose  designation and the percent change is written to a new .csv file with the intention of attempting sentiment analysis with the Win or Lose designations as the outcome and the Snippets as the sentiment. 


\begin{figure}[htb]
\begin{verbatim}
your code here 
\end{verbatim}
\caption{This Python script takes in the Date, Stock Ticker Symbol, and Snippet from the Google API .csv that was produced using both manual mining of the stock symbols and the python script provided for getting the Date and Snippet from Gmail. This code returns a modified .csv which lists an ``L'' for stocks that did not increase by 10\% in five days and a ``W'' for stocks that increased by at least 10\%. It also prints the stocks that increased by at least 10\% along with the highest price over 5 days, the starting price on the day that the Google Alert was received, and the percent change.}\label{c:stock}
\end{figure}

Figure \ref{c:stock} shows the code to combine the data produced by the Google Alert mining and available historic stock price data.

Fourteen out of sixty-three stock tickers returned by Google Alerts were flagged at ``Winners'' for increasing in price by 10\% within five days after the Google Alert was received. 
\begin{mdframed}[style=default]
\begin{lstlisting}
Ticker prctChange High Open Date
['ABEO'] 27.39 10.0 7.85 2017-08-22
['ARRY'] 15.41 10.11 8.76 2017-08-22
['BPMC'] 24.78 52.83 42.34 2017-08-22
['CHS'] 11.95 8.71 7.78 2017-11-22
['CLSN'] 160.9 3.47 1.33 2017-11-23
['EARS'] 20.83 0.87 0.72 2017-11-18
['EGLT'] 15.04 1.3 1.13 2017-11-17
['HCM'] 39.87 35.01 25.03 2017-11-19
['NLNK'] 57.8 10.02 6.35 2017-11-18
['NWBO'] 45.0 0.29 0.2 2017-11-19
['NWBO'] 45.0 0.29 0.2 2017-11-17
['ONCE'] 11.53 83.19 74.59 2017-08-21
['OTIC'] 11.47 20.9 18.75 2017-08-23
['PSTI'] 32.23 1.6 1.21 2017-11-22
['VTVT'] 10.92 5.08 4.58 2017-11-23
['VTVT'] 24.24 5.69 4.58 2017-11-19
['VTVT'] 24.24 5.69 4.58 2017-11-18
\end{lstlisting}
\end{mdframed}

\subsection{Data Analysis}
%text mining

%logistic regression


\section{Results}
There are many methods for analysis that could be implemented for this dataset. Time series prediction could be used to identify trends in the stocks of interest \cite{ARMANO}. Regression analysis is very common to identify key factors that contribute to the accuracy of a  prediction. TextBlob sentiment analysis allows for sentiment analysis to be performed in as little as four lines of code. TextBlob returns a number between -1 and 1 for how negative (-1) or positive (1) a defined sentiment or group of text is \cite{www-textblob}. Tensorflow is another popular way of creating sentiment analysis which takes an input of words with the intent of returning a sentiment of positive, negative, or neutral. In order to do this Tensorflow uses a build in learning and training set called tflearn to compare previously established sentiments. For example, words like ``love'' and ``happy'' return a positive sentiment while words like ``hate'' and ``sad'' return a negative sentiment \cite{www-oreilyTensor}. %Random Trees

The code that performs random tree analysis starts with some dependencies. Os is imported to allow for command line functionality, the machine learning library sklearn is used because it has a very fast learning rate, KaggleWord2VecUtility is a utility that processes raw text into segments for learning, pandas as mentioned before helps with delimited file manipulation, nltk that already contains a number of words and phrases that are not useful for sentiment analysis importing this library helps to eliminate those elements from the dataset we are training on. To install KaggleWord2VecUtility visit the DeepLearningMovies github directory \cite{kaggle}. 

In this code the Kaggle module removes special characters associated with HTML. It was intended to return a URL from the Google Alerts and run the website associates with each alert through beautiful-soup to use the entire article as training data, but the Gmail messages were encoded in such a way that it was not possible to extract the URL from the Google Alert. Nltk removes works such as ``to'' or ``the'' which do not hold any inherent meaning that could be applied to the sentiment analysis. 


\begin{figure}[htb]
\begin{verbatim}
your code here 
\end{verbatim}
\caption{The Sentiment Python code takes the .csv exported by the historical stock script and parses the Snippets to train on the stock script and apply it to more recent stock quotes and Google Alerts}\label{c:sentiment}
\end{figure}

Figure \ref{c:sentiment} shows the entire code to train on the dataset provided by the historical stock data and Google Alert sentiments.


The Python code for verifying the random tree analysis by pulling historical stock data for each ticker analyzed is propelled by pandas\_datareader. The script starts by reading in the .csv created using the random tree analysis script described previously. The data is read in as a dictionary using DictReader and the output file is opened/created right afterwards to allow for writing out with each loop through the starting file's dictionary. For each line the stock ticker and date are passed to a function that returns the highest price of the stock from the date of the received alert to the current date, the stock and ticker are then passed to a function that pulls the opening price on the day that the Google Alert was received. These two prices are compared to verify if the stock increased by 10\% from the time of the alert. The results export to a .csv as shown:
\begin{mdframed}[style=default]
\begin{lstlisting}
Accuracy,Date,Sentiment,Ticker
L,2017-12-03,L,ABBV
L,2017-12-01,L,ABBV
L,2017-11-30,L,ACAD
L,2017-12-02,L,ALNY
L,2017-12-03,L,ARGX
L,2017-12-02,L,BABA
\end{lstlisting}
\end{mdframed}
This analysis shows the stock ticker ABBV for the pharmaceutical company AbbVie as a ``loser'' twice as two alerts were received about the company on December 3 and 4. As of December 4 ABBV is down 1.08\% post Google Alert receipt. ACAD is the ticker for ACADIA Pharmaceuticals Inc. which is down 1.09\% since receipt of the Google Alert on November 30. Alnylam Pharmaceuticals, Inc (ALNY) is down 1.06\% since December 2. ARGX is down 0.97\% since receipt of the Google Alert but up over 18\% for the prior five days. ARGX did not appear in the training data set so it might be worth while to explore factors that contributed to it's recent increase, if not clinical trials. Interestingly, BABA is a Chinese e-commerce site which is down 2.88\%. This ticker appearing is cause to look closer at the article that was link to the Clinical Trial Alert but returned a retail chain.

\begin{figure}[htb]
\begin{verbatim}
your code here 
\end{verbatim}
\caption{This Python script takes in the Date and Stock Ticker Symbol from the sentiment .csv that was produced using the sentiment python script provided for performing a random forest analysis on the Google Alert results. This code returns a modified .csv which lists an ``L'' for stocks that did not increase by 10\% from the time the Alert was received to the current date and a ``W'' for stocks that increased by at least 10\%. It also prints the stocks that increased by at least 10\%  and were marked as ``winners'' by the sentiment script.}\label{c:result}
\end{figure}

Figure \ref{c:result} shows the code to combine the data produced by the random forest analysis and combine it with available historic stock price data.

\subsection{Comparison to Established Analyst Ratings}
%What did the analysts perdict about the companies analyzed?

%Goldman
%Chase
ARRY is a bio-pharmaceutical company that was call out in the training set as a ``winner'' for August 22. J P Morgan Chase \& Co confirmed a ``buy'' rating for ARRY on September 11, three weeks after it was identified by this model as a ``winner''.

%Morningstar


\section{Conclusion}
The codes provided for this project will take Google Alert data directly from a Gmail account, write the date the alert was received and the Snippet to a .csv, use the stock tickers identified in the Google Alerts to pull relevant historical stock price data to create a training set which is then analyzed using a random tree approach. The random tree analysis then produces a prediction for stocks that have received alerts more recently (within five days of the analysis). While all the sentiments drawn were indicated as ``losers'' none of the stocks were reconfirmed by recent historical data as significant increases. 

The analysis presented herein represents how sentiment expressed in news reports about clinical trials has the potential to predict the movement of stock prices. Further analysis should work with a bigger data set, possibly by increasing the number of configured Google Alerts and certainly by identifying how to pull stock tickers from the Snippets. 

\begin{acks}

The author would like to thank Dr. Gregor von Laszewski and the teaching assistants of the Fall 2017 i523 course for their support and suggestions to write this paper.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 


\end{document}
